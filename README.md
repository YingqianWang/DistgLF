## *<center>Disentangling Light Fields for Super-Resolution and Disparity Estimation</center>*

***<center><a href="https://yingqianwang.github.io" target="_blank">Yingqian Wang</a>&emsp; <a href="https://longguangwang.github.io/" target="_blank">Longguang Wang</a>&emsp;  <a href="https://gaochangwu.github.io/" target="_blank">Gaochang Wu</a>&emsp; Jungang Yang&emsp; Wei An&emsp; Jingyi Yu&emsp; <a href="http://yulanguo.me/" target="_blank">Yulan Guo</a></center>*** <br>

### <p align="center"> <a href="https://yingqianwang.github.io/DistgLF/videos/demo.mp4"><img src="" width="80%"></a> </p>

***Light field (LF) cameras record both intensity and directions of light rays, and encode 3D cues into 4D LF images. Recently, many convolutional neural networks (CNNs) have been proposed for various LF image processing tasks. However, it is challenging for CNNs to effectively process LF images since the spatial and angular information are highly inter-twined with varying disparities. In this paper, we propose a generic mechanism to disentangle these coupled information for LF image processing. Specifically, we first design a class of domain-specific convolutions to disentangle LFs from different dimensions, and then leverage these disentangled features by designing task-specific modules. Our disentangling mechanism can well incorporate the LF structure prior and effectively handle 4D LF data. Based on the proposed mechanism, we develop three networks (i.e., DistgSSR, DistgASR and DistgDisp) for spatial super-resolution, angular super-resolution and disparity estimation. Experimental results show that our networks achieve state-of-the-art performance on all these three tasks, which demonstrates the effectiveness, efficiency, and generality of our disentangling mechanism.***<br><br><br>
